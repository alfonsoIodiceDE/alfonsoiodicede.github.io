---
title: "Biplots in dimension reduction and clustering"
author: "Alfonso Iodice D'Enza, Michel van de Velden and Angelos Markos"
# subtitle: "IFCS 2022"  
date: "21 July 2022"
output:
  xaringan::moon_reader:
    css: xaringan-themer.css
    nature:
      navigation:
        scroll: false
      slideNumberFormat: "%current%"
      highlightStyle: github
      highlightLines: true
      ratio: 16:9
      countIncrementalSlides: false
---
```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
xaringanExtra::use_animate_css()
# xaringanExtra::use_scribble()
knitr::opts_chunk$set(
  fig.width = 8, fig.height = 6, fig.retina=5,
  out.width = "75%",
  cache = FALSE,
  echo = TRUE,
  message = FALSE, 
  warning = FALSE,
  hiline = TRUE
)


```

```{r, load_refs, include=FALSE, cache=FALSE}
# remotes::install_github("ROpenSci/bibtex")
library(RefManageR)
BibOptions(check.entries = FALSE,
       bib.style = "authoryear",
       cite.style = "authoryear",
       style = "markdown",
       hyperlink = FALSE,
       dashed = FALSE)
ifcs_bib <- ReadBib("ifcs22_references.bib", check = FALSE)
```

```{r xaringan-themer, include=FALSE, warning=FALSE}
library(xaringanthemer)
library(xaringanExtra)
library(FactoMineR)
library("gganimate")
library(magick)
library(palmerpenguins)
library(fastDummies)
library(mlbench)
library(tidyverse)
library(purrr)
library(ca)
library("magick")
library(tidymodels)
library(discrim)
library(clustrd)
library(flipbookr)
library(kableExtra)
library(janitor)
library(patchwork)
library(mvtnorm)
source("R/plot_ca_da.r")
style_duo_accent(primary_color = "#F9B76C",
                 secondary_color = "#37499c",
                 title_slide_background_image = "./figures/ifcs_2022_logo.png",
                 title_slide_background_position = "bottom",
                 title_slide_background_size= "40%",
                 title_slide_text_color = "#37499c",
                 code_font_size  = "0.7rem",
                 code_highlight_color="#E4F6EF",
                 header_color = "#37499c"
                 )
                 
style_extra_css(css = list(
  ".my-pull-left"= list(float= "left",
                         width = "10%"),
  ".my-pull-right"= list(float= "right",
                          width = "89%"),
  ".my-pull-right + *" = list(clear = "both")
  ),
  outfile = "xaringan-themer.css",
  append = TRUE)


xaringanExtra::use_tile_view()
```

class: animated fadeIn 

### stacked data reduction (stacked DR)
- <h4 style = "color:#37499c"> variables and sample reduction </h4>

- <h4 style = "color:#37499c"> the tandem approach and  cluster masking problem </h4>

--

### joint DR
- <h4 style = "color:#37499c"> a unified framework for continuous, categorical and mixed data </h4>

--

### biplots in joint DR for cluster characterization

- <h4 style = "color:#37499c"> discriminant analysis biplot, contribution biplot </h4>


---
class: animated fadeIn inverse center middle

## stacked DR
### also known as 
###  the tandem approach

---
class: animated fadeIn middle

### data reduction paradigm

 **summarising** a two-way data matrix by **aggregating measurements** 
`r Citep(bib = ifcs_bib, "farcomeni2016robust")`

- column-wise reduction: define a limited number of linear combinations (**dimension reduction**)

- row-wise reduction: define a limited number of observations, each representative of an homogeneous group (**partitioning clustering**)

---
class: animated fadeIn
### continuous data case: principal component analysis 

${\bf X}$ is the $n \times p$ standardized data matrix

The PCA loss function can be defined as:

$$\min_{\mathbf{A,B}}\left\Vert \mathbf{Y}-n^{1/2}\mathbf{AB}^{\sf T}p^{1/2}\right\Vert ^{2} \ \ s.t. \ \
p\mathbf{B}^{\sf T}\mathbf{B}=\mathbf{I}_{d}$$

where $\mathbf{Y}=n^{-1/2}\mathbf{X}p^{-1/2}$.

--

- the columns of $\mathbf{A}=n^{1/2}\mathbf{\tilde{U}{\bf \tilde{D}}_{\alpha}}$ are the row (principal) coordinates, and they are such that
$\frac{1}{n}\mathbf{A}^{\sf T}\mathbf{A}={\bf \tilde{D}}_{\alpha}^{2}$

- the columns of $\mathbf{B}=p^{1/2}{\bf \tilde{V}}$ are the column (standard) coordinates

--

Since ${\bf \tilde{U}}{\bf \tilde{D}_{\alpha}}{\bf \tilde{V}^{{\sf T}}}$ is the $d$-truncated SVD of $\bf{Y}$, then
$n^{1/2}\mathbf{AB}^{\sf T}p^{1/2}$ is the best rank- $d$ approximation of $\bf{Y}$, in the least square sense.


---
class: animated fadeIn
### categorical data case:  correspondence analysis

${\bf P}$ is a two-way table with relative frequencies, crossing two categorical variables, with  $q_{r}$ and $q_{c}$ categories

The CA loss function is:

$$\min_{\mathbf{A,B}}\left\Vert \mathbf{\tilde{P}-D}_{r}^{1/2}\mathbf{AB}^{\sf T}\mathbf{D}_{c}^{1/2}\right\Vert ^{2} \ \ s.t. \ \
\mathbf{B}^{\sf T}\mathbf{D}_{c}\mathbf{B}=\mathbf{I}_{d}$$

where $\mathbf{\tilde{P}=D}_{r}^{-1/2}\left(\mathbf{P}-\mathbf{rc}^{\sf T}\right)\mathbf{D}_{c}^{-1/2}$ , $\mathbf{r=P1}_{q_c}$ , $\mathbf{c} =\mathbf{P}^{\sf T}\mathbf{1}_{q_r}$,
$\mathbf{D}_{r}=diag(\mathbf{r})$, $\mathbf{D}_{c} = diag(\mathbf{c})$ 

--

- the columns of $\mathbf{A=D}_{r}^{-1/2}\mathbf{\tilde{U}{\bf \tilde{D}}_{\alpha}}$ are the row (principal) coordinates, and they are such that
$\mathbf{A}^{\sf T}\mathbf{D}_{r}\mathbf{A={\bf D}_{\alpha}}^{2}$

- the columns of $\mathbf{B=D}_{c}^{-1/2}\mathbf{\tilde{V}}$ are the column (standard) coordinates

--

Since ${\bf \tilde{U}}{\bf \tilde{D}_{\alpha}}{\bf \tilde{V}^{{\sf T}}}$ is the $d$-truncated SVD of $\bf{Y}$, then
$\mathbf{D}_{r}^{1/2}\mathbf{AB}^{\sf T}\mathbf{D}_{c}^{1/2}$ is the best rank- $d$ approximation of $\bf{Y}$, in the least square sense.



---
class: animated fadeIn
### categorical data case: (multiple) correspondence analysis

MCA generalizes the application of CA to $p$ categorical variables, each with $q_{j}$ categories, $j=1,\ldots,p$.

- ${\bf Z}^{\star}_{j}$ is the one-hot-encoding of the $j^{th}$ categorical variable.

- ${\bf Z}^{\star}=[{\bf Z}^{\star}_{1},\ldots,{\bf Z}^{\star}_{p}]$ and ${\bf Z}=\frac{{\bf Z}^{\star}}{n\times Q}$, with $Q=\sum_{j=1}^{p}{q_{j}}$; 

- the margins are ${\bf r}=\frac{1}{n}{\bf 1}_{n}$ and ${\bf s}={\bf Z}^{{\sf T}}{\bf 1}_{n}$  

--

The (M)CA loss function is:

$$\min_{\mathbf{A,B}}\left\Vert \mathbf{\tilde{Z}} - \frac{1}{\sqrt{n}}\mathbf{AB}^{\sf T}\mathbf{D}_{s}^{1/2}\right\Vert ^{2} \ \ s.t. \ \
\mathbf{B}^{\sf T}\mathbf{D}_{s}\mathbf{B}=\mathbf{I}_{d}$$
where $\mathbf{\tilde{Z}}=\sqrt{n}\left(\mathbf{Z}-\frac{1}{n}{\bf 1}_{n}{\bf 1}_{n}^{{\sf T}}{\bf Z}\right)\mathbf{D}_{s}^{-1/2}$

---
class: animated fadeIn
### mixed data case: factor analysis of mixed data

Real datasets have often both continuous and categorical variables.

Upon an appropriate data pre-processing, dimension reduction is done via PCA.

--

Let $\bf X$ contain the continuous variables (centered and standardised);

Let the $\bf Z$ also be centered and standardized:

--

 - the centering operator is ${\bf M} = {\bf I}_{n} - n^{-1}{\bf 1}_{n}{\bf 1}^{{\sf T}}_{n}$ 
 - the scaling weights are in ${\bf D}_{z}=diag({\bf Z}^{\sf T}{\bf Z})$ 
 
The PCA of ** ${\bf X^{\star}} = \left[{\bf X} \ {\bf D}_{z}^{-1/2}{\bf Z}{\bf M}\right]$ ** is the FAMD

---
class: animated fadeIn
### partitioning cluster analysis

---
class: animated fadeIn
### curse of dimensionality?

```{r, echo=FALSE,fig.align='center',out.width="40%"}
magick::image_read_pdf("./figures/neighbours0_av.pdf",
                       pages = 1)
```

---
class: animated fadeIn
### curse of dimensionality?

```{r, echo=FALSE,fig.align='center',out.width="40%"}
magick::image_read_pdf("./figures/neighbours01_av.pdf",
                       pages = 1)
```



---
class: animated fadeIn
### curse of dimensionality?

```{r, echo=FALSE,fig.align='center',out.width="40%"}
magick::image_read_pdf("./figures/neighbours1_av.pdf",
                       pages = 1)
```

---
class: animated fadeIn
### curse of dimensionality?

```{r, echo=FALSE,fig.align='center',out.width="40%"}
magick::image_read_pdf("./figures/neighbours02_av.pdf",
                       pages = 1)
```


---
class: animated fadeIn
### curse of dimensionality?

```{r, echo=FALSE,fig.align='center',out.width="40%"}
magick::image_read_pdf("./figures/neighbours2_av.pdf",
                       pages = 1)
```

---
class: animated fadeIn
### stacking variables and samples reduction

Practitioners often apply dimension reduction and then cluster the low-dimensional scores: this approach is referred to as ** tandem analysis ** `r Citep(bib=ifcs_bib,"arabie1996advances")`

- mitigate the effects of the curse of dimensionality

- the graphical display of the dataset at hand may be of help for cluster characterization

- 


---
class: animated fadeIn
### cluster masking

Consider a toy example: three very well separated clusters in two dimensions


```{r,echo=FALSE}
source("R/points_in_a_circle.R")
mat=matrix(c(2,2,5,8,6,5),ncol=2,byrow = T)
centers = tibble(c_d1=mat[,1],c_d2=mat[,2],true_cluster=letters[1:nrow(mat)]) 
# centers %>% kbl %>% kable_styling(font_size =14)
```


```{r,fig.align='center',echo=FALSE,out.width="45%",eval=TRUE,cache=FALSE}
set.seed(123)
toy_points = centers %>% mutate(
  cluster_points=map2(.x = c_d1,.y=c_d2,.f=~points_in_a_circle(c_d1=.x,c_d2=.y,n=50))
  ) %>% unnest(cluster_points) 

pca_points = toy_points %>% dplyr::select(d1,d2) %>% PCA(graph=FALSE) %>%
  .[["ind"]] %>% .[["coord"]] %>%
  as_tibble() %>% dplyr::rename(pc1=`Dim.1`,pc2=`Dim.2`) %>%
  cbind(toy_points) %>% select(pc1,pc2,true_cluster) %>% 
  dplyr::rename(d1=`pc1`,d2=`pc2`) %>% mutate(display="pca")
      
animation_points = bind_rows(toy_points  %>%
                               dplyr::select(d1,d2,true_cluster) %>% 
                               mutate(display="original"),pca_points)

pca_toy = animation_points %>% 
  ggplot(aes(x=d1,y=d2))+geom_point(aes(shape=true_cluster),alpha=.75,size=5) +
  theme_minimal() + geom_vline(xintercept=0, alpha=.75) + geom_hline(yintercept=0, alpha=.75)+
  transition_states(display,wrap = FALSE,transition_length = 1) +
    view_follow() + theme(legend.position="none")

# anim_save(filename = "./figures/pca_toy_anim.gif",pca_toy)
knitr::include_graphics("./figures/pca_toy_anim.gif")

tandem_points = pca_points %>% 
mutate(cluster=kmeans(x=pca_points %>% dplyr::select(d1,d2),centers=3,nstart = 10)$cluster %>% as_factor() )


```


---
class: animated fadeIn
### cluster masking

the PCA scores are easily clustered via, e.g., Kmeans

```{r,fig.align='center',echo=FALSE,out.width="45%",eval=TRUE,cache=FALSE}
tandem_points %>% 
  ggplot(aes(x=d1,y=d2))+geom_point(aes(shape=true_cluster,color=cluster),alpha=.75,size=5)+
  theme_minimal() + geom_vline(xintercept=0, alpha=.75) + geom_hline(yintercept=0, alpha=.75)+
   theme(legend.position="none")

```

---
class: animated fadeIn
### cluster masking

the toy example: adding 4 noise variables  $X_{j}\sim N(0,6), \ j=3,\ldots,6$. 

```{r,fig.align='center',echo=FALSE,out.width="45%",eval=TRUE,cache=FALSE}
set.seed(123)
  toy_points = centers %>% mutate(
  cluster_points=map2(.x = c_d1,.y=c_d2,.f=~points_in_a_circle(c_d1=.x,c_d2=.y,n=50))
  ) %>% unnest(cluster_points) 

# corr_1 = matrix(3,2,2)
# corr_2 = matrix(-1,2,2)
# diag(corr_1) =3
# diag(corr_2) =6
# 
# noise_vars=rmvnorm(n = nrow(toy_points),mean=c(0,0),sigma = corr_1)
# noise_vars_2=rmvnorm(n = nrow(toy_points),mean=c(0,0),sigma = corr_2)
# 
# toy_points_noise = toy_points %>% dplyr::select(d1,d2,true_cluster) %>%
#   mutate(d3=noise_vars[,1],
#          d4=noise_vars[,2],
#          d5=noise_vars_2[,1],
#          d6=noise_vars_2[,2]
#          )

toy_points_noise = toy_points %>% dplyr::select(d1,d2,true_cluster) %>%
  mutate(d3=rnorm(nrow(toy_points),0,6),
         d4=rnorm(nrow(toy_points),0,9),
         d5=rnorm(nrow(toy_points),0,6),
         d6=rnorm(nrow(toy_points),0,6)
         )
```
---
class: animated fadeIn
### cluster masking

the toy example: adding 4 noise variables  $X_{j}\sim N(0,6), \ j=3,\ldots,6$. 

```{r,fig.align='center',echo=FALSE,out.width="45%",eval=TRUE,cache=FALSE}

toy_points_noise %>%   mutate(
cluster_full = kmeans(x=toy_points_noise %>% select(starts_with("d")), centers=3,nstart = 10)$cluster %>% as_factor()
) %>% 
  ggplot(aes(x=d1,y=d2))+geom_point(aes(shape=true_cluster,color=cluster_full),alpha=.75,size=5)+
  theme_minimal() + geom_vline(xintercept=0, alpha=.75) + geom_hline(yintercept=0, alpha=.75)+
   theme(legend.position="none")+ggtitle("Kmeans results in full dimensions")


# sc_toy_points_noise = toy_points_noise %>% dplyr::select(starts_with("d")) %>% 
#   mutate(across(everything(),.fns= ~scale(.x)))
# 
# 
# write.csv(file = "data/toy_points_noise.csv", x = sc_toy_points_noise)

pca_points = toy_points_noise %>% dplyr::select(starts_with("d")) %>% PCA(graph=FALSE,ncp = 6) %>%
  .[["ind"]] %>% .[["coord"]] %>%
  as_tibble() %>% dplyr::rename(pc1=`Dim.1`,pc2=`Dim.2`,
                                pc3=`Dim.3`,pc4=`Dim.4`,
                                pc5=`Dim.5`,pc6=`Dim.6`) %>%
  cbind(toy_points) %>% select(pc1:pc6,true_cluster) %>% 
  dplyr::rename(d1=`pc1`,d2=`pc2`) %>% mutate(display="pca")


animation_points = bind_rows(toy_points_noise  %>%
                               dplyr::select(d1,d2,true_cluster) %>% 
                               mutate(display="original"),pca_points %>% 
                               dplyr::select(d1,d2,true_cluster,display))

tandem_toy = animation_points %>% 
  ggplot(aes(x=d1,y=d2))+geom_point(aes(shape=true_cluster),alpha=.75,size=5)+
  theme_minimal() + geom_vline(xintercept=0, alpha=.75) + geom_hline(yintercept=0, alpha=.75)+
  transition_states(display,wrap = FALSE,transition_length = 1) +
    view_follow() + theme(legend.position="none")
```

---
class: animated fadeIn
### cluster masking

The tandem approach: the 2-d PC map

```{r,fig.align='center',echo=FALSE,out.width="45%",eval=TRUE,cache=FALSE}
 # anim_save(filename = "./figures/tandem_toy_anim.gif",tandem_toy)
knitr::include_graphics("./figures/tandem_toy_anim.gif")

tandem_points = pca_points %>% 
mutate(
  cluster_2d=kmeans(x=pca_points %>% dplyr::select(d1,d2),centers=3,nstart = 10)$cluster %>% as_factor(), 
  cluster_3d=kmeans(x=pca_points %>% dplyr::select(d1:pc3),centers=3,nstart = 10)$cluster %>% as_factor(),
  cluster_4d=kmeans(x=pca_points %>% dplyr::select(d1:pc4),centers=3,nstart = 10)$cluster %>% as_factor(),
  cluster_5d=kmeans(x=pca_points %>% dplyr::select(d1:pc5),centers=3,nstart = 10)$cluster %>% as_factor(),
  cluster_6d=kmeans(x=pca_points %>% dplyr::select(d1:pc6),centers=3,nstart = 10)$cluster %>% as_factor())


```

---
class: animated fadeIn
### cluster masking

The tandem approach will fail: the 2-d PC map does not display clustered observations

```{r,fig.align='center',echo=FALSE,out.width="45%",eval=TRUE,cache=FALSE}

tandem_points %>% mutate(od1=toy_points_noise$d1,
                         od2=toy_points_noise$d2) %>% 
  ggplot(aes(x=d1,y=d2))+geom_point(aes(shape=true_cluster,color=cluster_2d),alpha=.75,size=5)+
  theme_minimal() + geom_vline(xintercept=0, alpha=.75) + geom_hline(yintercept=0, alpha=.75)+
  theme(legend.position="none")
```
---
class: animated fadeIn
### cluster masking

The tandem approach will fail: K-means considering an increasing number of PCs

```{r,fig.align='center',echo=FALSE,out.width="45%",eval=TRUE,cache=FALSE}
tandem_points %>% mutate(od1=toy_points_noise$d1,
                         od2=toy_points_noise$d2) %>% 
  ggplot(aes(x=od1,y=od2))+geom_point(aes(shape=true_cluster,color=cluster_3d),alpha=.75,size=5)+
  theme_minimal() + geom_vline(xintercept=0, alpha=.75) + geom_hline(yintercept=0, alpha=.75)+
  theme(legend.position="none")+ggtitle("Kmeans results on 3 pc's")
```


---
class: animated fadeIn
### cluster masking

The tandem approach will fail: K-means considering an increasing number of PCs

```{r,fig.align='center',echo=FALSE,out.width="45%",eval=TRUE,cache=FALSE}
tandem_points %>% mutate(od1=toy_points_noise$d1,
                         od2=toy_points_noise$d2) %>% 
  ggplot(aes(x=od1,y=od2))+geom_point(aes(shape=true_cluster,color=cluster_4d),alpha=.75,size=5)+
  theme_minimal() + geom_vline(xintercept=0, alpha=.75) + geom_hline(yintercept=0, alpha=.75)+
  theme(legend.position="none")+ggtitle("Kmeans results on 4 pc's")
```

---
class: animated fadeIn
### cluster masking

The tandem approach will fail: K-means considering an increasing number of PCs

```{r,fig.align='center',echo=FALSE,out.width="45%",eval=TRUE,cache=FALSE}
tandem_points %>% mutate(od1=toy_points_noise$d1,
                         od2=toy_points_noise$d2) %>% 
  ggplot(aes(x=od1,y=od2))+geom_point(aes(shape=true_cluster,color=cluster_5d),alpha=.75,size=5)+
  theme_minimal() + geom_vline(xintercept=0, alpha=.75) + geom_hline(yintercept=0, alpha=.75)+
  theme(legend.position="none")+ggtitle("Kmeans results on 5 pc's")
```


---
class: animated fadeIn
### cluster masking

The tandem approach will fail: K-means considering an increasing number of PCs

```{r,fig.align='center',echo=FALSE,out.width="45%",eval=TRUE,cache=FALSE}
tandem_points %>% mutate(od1=toy_points_noise$d1,
                         od2=toy_points_noise$d2) %>% 
  ggplot(aes(x=od1,y=od2))+geom_point(aes(shape=true_cluster,color=cluster_6d),alpha=.75,size=5)+
  theme_minimal() + geom_vline(xintercept=0, alpha=.75) + geom_hline(yintercept=0, alpha=.75)+
  theme(legend.position="none")+ggtitle("Kmeans results on 6 pc's")
```


---
class: animated fadeIn inverse center middle

## joint data reduction (JDR)


---
class: animated fadeIn

### Beyond tandem analysis: joint methods

**Methods for continuous data**


- **Reduced K-means** `r Citep(bib = ifcs_bib, "De_Soete")`: joint PCA + Kmeans
- **Factorial K-means** `r Citep(bib = ifcs_bib, "vichi2001factorial")`: joint PCA + Kmeans

**Methods for categorical data**


- **MCA-Kmeans** `r Citep(bib = ifcs_bib, "Hwang")`: joint MCA + Kmeans
- **iFCB** `r Citep(bib = ifcs_bib, "iodice2013iterative")`: iterative sequential NSCA + Kmeans
- **Cluster Correspondence Analysis** `r Citep(bib = ifcs_bib, "van_de_velden17")`: joint CA + Kmeans

**Methods for mixed data**

- cluster and dimension reduciton for mixed data `r Citep(bib=ifcs_bib, "vichi2019clustering",before="CDR, ")`
- **Groupals** `r Citep(bib=ifcs_bib, "van1989clust",before="CDR, ")`


--
All methods are implemented in $\texttt{CRAN}$ package $\texttt{clustrd}$ `r Citep(bib = ifcs_bib,"Mark_clustrd")`

---
class: animated fadeIn
### JDR: a unified framework

The general objective can be formulated as follows `r Citep(bib = ifcs_bib, "yamamoto2014general","vichi2019clustering")`:
 
 $$
 \min\phi\left(\mathbf{B},\mathbf{Z}_{K}\right)=
 \alpha\left\Vert\mathbf{X} - \mathbf{X}\mathbf{B}\mathbf{B}^{\prime}\right\Vert ^{2} +
 (1-\alpha)\left\Vert\mathbf{XB} - \mathbf{P}\mathbf{X}\mathbf{B}\right\Vert ^{2} 
 $$
 


$\mathbf{P} = \mathbf{Z}_{K}\left(\mathbf{Z}_{K}^\prime\mathbf{Z}_{K}\right)^{-1}\mathbf{Z}_{K}^\prime$: a projection matrix

${\bf G} = \mathbf{P}\mathbf{X}\mathbf{B}$: $K \times d$ cluster centroid matrix

- $\alpha = 1/2$, **Reduced K-means**
- $\alpha = 0$, **Factorial K-means**

Note that $\alpha = 1$ gives the PCA solution.

---
class: animated fadeIn
### JDR: a unified framework

$$
\min\phi\left(\mathbf{B},\mathbf{Z}_{K}\right)=
\alpha\left\Vert\mathbf{X} - \mathbf{X}\mathbf{B}\mathbf{B}^{\prime}\right\Vert ^{2} +
(1-\alpha)\left\Vert\mathbf{XB} - \mathbf{P}\mathbf{X}\mathbf{B}\right\Vert ^{2} \ \ \ (1)
$$

**Extensions to categorical data**

$$\mathbf{X}^{cat} = \mathbf{D}_{z}^{-1/2}\mathbf{MZ}$$

- $\alpha = 1/2$, Cluster Correspondence Analysis

**Extensions to mixed-type data**
$$\mathbf{X}^{mix} = \left[\mathbf{X}^{cnt} \hspace{.35cm}  \mathbf{X}^{cat}\right]$$

- $\alpha = 1/2$, Mixed Reduced K-means
- $\alpha = 0$, Mixed Factorial K-means

Note that $\alpha = 1$ gives the PCAMIX/FAMD solution.

---
class: animated fadeIn
### JDR: a unified procedure


For given $\alpha$, the following ALS algorithm is used to minimize the loss function  `r Citep(bib = ifcs_bib, "van_de_velden")`:


- Generate an initial cluster allocation $\mathbf{Z}_{K}$ (e.g., by randomly assigning subjects to clusters).
	
- Find loadings $\mathbf{B}$ by taking the eigendecomposition of $\mathbf{X}^{\prime}\left((1-\alpha)\mathbf{P} - (1-2\alpha)\mathbf{I}\right)\mathbf{X}$
	
- Update the cluster allocation $\mathbf{Z}_{K}$ by applying K-means to the reduced space subject coordinates $\mathbf{X}\mathbf{B}$
	
- Repeat the procedure (i.e. go back to step 2) using $\mathbf{Z}_{K}$ for the cluster allocation matrix, until convergence.\ That is, until
	$\mathbf{Z}_{K}$ remains constant.




---
class: animated fadeIn

### JDR on the toy data set: no more cluster masking

```{r, echo=FALSE, fig.align='center',message=FALSE,out.width="45%",cache=FALSE}

fkm_scores = read.csv(file = "data/toy_FKM_scores.csv",sep = ";") %>% as_tibble()%>% 
  mutate(cluster=rep(c("a","b","c"),each=50))

fkm_scores %>% ggplot(aes(x = d1, y = d2)) + 
  geom_point(aes(color=cluster,shape=cluster),alpha=.75,size=5) + 
  theme_minimal() + geom_vline(xintercept=0, alpha=.75) + geom_hline(yintercept=0, alpha=.75)+
  theme(legend.position="none")+ggtitle("FKM results")


```


---
class: animated fadeIn inverse center middle

## biplots in JDR
### for
### cluster characterization

---
class: animated fadeIn middle
### The Palmer Penguins data set (not iris)


---
class: animated fadeIn middle
### The Palmer Penguins: tandem 

```{r, echo=FALSE, fig.align='center',message=FALSE,out.width="45%",cache=FALSE}
set.seed(1234)
pengs = penguins %>% select(species,ends_with("_mm"),ends_with("_g")) %>% na.omit
pca_pengs = PCA(pengs %>% select(ends_with("_mm"),ends_with("_g")),graph=FALSE)
kmeans_sol = kmeans(pca_pengs$ind$coord[,1:2],3,2,nstart=100)$cluster  

scores_pca = pca_pengs$ind$coord %>% as_tibble() %>% select(1,2) %>% rename(d1=Dim.1,d2=Dim.2)%>%
  mutate(cluster = fct_inorder(factor(kmeans_sol)),
         cluster=fct_recode(cluster,a="2",b="1",c="3"),
         mtd="tandem",what="obs", true_cluster = pengs %>% pull(species))


scores_rkm = read.csv("data/penguin_scores_RKM.csv",sep=";") %>% 
  mutate(cluster=factor(cluster),
  cluster=fct_recode(cluster,a="1",b="2",c="3"),
  mtd="rkm",what="obs",d2 = d2*-1, true_cluster = pengs %>% pull(species))
   
scores_fkm = read.csv("data/penguin_scores_FKM.csv",sep=";")%>% 
  mutate(cluster=factor(cluster),
         cluster=fct_recode(cluster,a="1",b="2",c="3"),
         mtd="fkm",what="obs",true_cluster = pengs %>% pull(species))
                                                                             

vars_rkm = read.csv("data/vars_penguin_RKM.csv",sep=";") %>% mutate(mtd="rkm",what="vars",d2 = d2*-1)
vars_fkm = read.csv("data/vars_penguin_FKM.csv",sep=";") %>% mutate(mtd="fkm",what="vars") %>% rename(varname=var_names)

varname=rownames(pca_pengs$var$coord)          

vars_pca  = pca_pengs$var$coord %>% as_tibble() %>% select(1,2) %>% 
  mutate(varname=varname,mtd="tandem",what="vars") %>% rename(d1=Dim.1,d2=Dim.2)

all_scores=rbind(scores_pca,scores_rkm, scores_fkm) %>% mutate(mtd=fct_inorder(mtd))
all_vars = rbind(vars_pca,vars_rkm,vars_fkm)

selected_scores = all_scores %>% filter(mtd %in% c("tandem","rkm")) %>% mutate(mtd=fct_drop(mtd))
selected_vars = all_vars %>% filter(mtd %in% c("tandem","rkm")) %>% mutate(mtd=fct_drop(mtd))

tandem_to_rkm = selected_scores   %>%
  ggplot(aes(d1,d2,color=cluster, shape=true_cluster)) + geom_point()+
  geom_segment(data=selected_vars,aes(x=0,xend=d1,y=0,yend=d2),
                 arrow=arrow(length = unit(.1,"inches")),
               color="dodgerblue",inherit.aes = FALSE) +
  theme_minimal() + theme(legend.position="none")+
  geom_text(data=selected_vars,aes(x=d1,y=d2,label=varname),inherit.aes = FALSE)+
  transition_states(states = mtd,wrap = FALSE,transition_length = 1) +  view_follow()

 anim_save(filename="./figures/tandem_to_rkm_anim.gif", tandem_to_rkm)

# all_scores

# table(pengs %>% pull(species),scores_pca$cluster)
# table(pengs %>% pull(species),scores_fkm$cluster)
# table(pengs %>% pull(species),scores_rkm$cluster)
# table(scores_pca$cluster,scores_rkm$cluster)


fkm_map = scores_fkm %>% ggplot(aes(d1,d2))+geom_point(aes(color=cluster, shape=cluster))+
   geom_segment(data=vars_fkm,aes(x=0,xend=d1,y=0,yend=d2,group = 1L),
                 arrow=arrow(length = unit(.1,"inches")),color="dodgerblue",inherit.aes = FALSE)+
  geom_label(data=vars_fkm,aes(x=d1,y=d2,label=varname)) +
  theme(legend.position = "none") + ggtitle("FKM")+theme_minimal()

rkm_map = scores_rkm %>% ggplot(aes(d1,d2))+geom_point(aes(color=cluster, shape=cluster),alpha=.5) +
   geom_segment(data=vars_rkm,aes(x=0,xend=d1,y=0,yend=d2,group = 1L),
                 arrow=arrow(length = unit(.1,"inches")),color="dodgerblue",inherit.aes = FALSE)+
  geom_label(data=vars_rkm,aes(x=d1,y=d2,label=varname),inherit.aes = FALSE)+
  theme(legend.position = "none") + ggtitle("RKM")+theme_minimal()

pca_map = scores_pca %>% ggplot(aes(d1,d2))+geom_point(aes(color=cluster, shape=cluster))+
   geom_segment(data=vars_pca,aes(x=0,xend=d1,y=0,yend=d2,group = 1L),
                 arrow=arrow(length = unit(.1,"inches")),color="dodgerblue",inherit.aes = FALSE)+
geom_label(data=vars_pca,aes(x=d1,y=d2,label=varname),inherit.aes = FALSE)+
  theme(legend.position = "none") + ggtitle("tandem")+theme_minimal()

pca_map

```

---
class: animated fadeIn 
### The Palmer Penguins: tandem to RKM


```{r, echo=FALSE, fig.align='center',message=FALSE,out.width="45%",cache=FALSE}
knitr::include_graphics("./figures/tandem_to_rkm_anim.gif")         
```

---
class: animated fadeIn 
### The Palmer Penguins:  RKM


```{r, echo=FALSE, fig.align='center',message=FALSE,out.width="45%",cache=FALSE}
rkm_map
```


---
class: animated fadeIn middle
### The zoo dataset
This is a dataset from the UCI repo `r Citep(bib = ifcs_bib,"blake1998uci","Leisch_mlbench")` 


- **82** animals of four types: **mammal**, **bird**, **fish** and **insect**

- **16** categorical variables describing the animals characteristics



---
class: animated fadeIn
### The zoo dataset

```{r,fig.align='center',echo=FALSE,out.width="45%", include=FALSE}
data(Zoo)
Zoo = as_tibble(Zoo) %>% filter(type %in% c("mammal","bird","fish","insect")) %>% 
  mutate(across(everything(),as_factor))
```

```{r,fig.align='center',echo=FALSE,out.width="45%", include=FALSE,cache=FALSE}
animal_names=rownames(Zoo)
type = Zoo %>% mutate(type= fct_drop(type)) %>% pull(type)
Zoo = Zoo %>% select(-type)
zoo_cca = clusmca(Zoo,nclus=4,ndim = 3,nstart=100,gamma = TRUE)
Zk = dummy_columns(zoo_cca$cluster,remove_selected_columns = TRUE) %>% data.matrix()
colnames(Zk) = str_replace(colnames(Zk),pattern = ".data",replacement = "cluster" )
Z_zoo = dummy_columns(Zoo,remove_selected_columns = TRUE) %>% data.matrix()

Zk_Z_zoo = t(Zk) %*% Z_zoo
zoo_ca = ca(t(Zk_Z_zoo))
discarded_rows = zoo_ca$rownames  %>% str_which("_FALSE")
zoo_ca$rowcoord = zoo_ca$rowcoord[-discarded_rows,]
zoo_ca$rownames = zoo_ca$rownames[-discarded_rows] %>% str_remove(pattern="_TRUE")
zoo_ca$rowmass = zoo_ca$rowmass[-discarded_rows]
all_plots = plot_ca_da(zoo_ca,thresh = .5)
```

```{r,fig.align='center',echo=FALSE,out.width="45%", message=FALSE}
all_plots$col_biplot
```

---
class: animated fadeIn
### The zoo: asymmetric map to contribution biplot

```{r,fig.align='center',echo=FALSE,out.width="45%"}
# zoo_contr_anim = all_plots$ani_biplot
# anim_save(filename="./figures/zoo_contr_anim.gif", zoo_contr_anim)
knitr::include_graphics("./figures/zoo_contr_anim.gif")
```

---
class: animated fadeIn
### The zoo: asymmetric map to contribution biplot

```{r,fig.align='center',echo=FALSE,out.width="45%"}
all_plots$contribution_biplot
```



---
class: animated fadeIn

### References

```{r ,echo=FALSE, results='asis'}
PrintBibliography(ifcs_bib, start = 1, end = 7)
```

---
class: animated fadeIn

### References (2)

```{r ,echo=FALSE, results='asis'}
PrintBibliography(ifcs_bib, start = 8)
```

